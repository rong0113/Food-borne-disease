{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caculate the weather data of each outbreak---Noro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a03c9a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b8574d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "noro_station = pd.read_csv('/Users/evelyn/Desktop/weather information/noro_station.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d57ff6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "noro = pd.read_excel('/Users/evelyn/Desktop/project/Cleaned data - Salmonella and norovirus.xlsx', sheet_name = 'Norovirus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f5565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noro_station = noro_station.dropna(subset = ['USAF'])\n",
    "noro_station = noro_station.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5982a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "noro_station[\"WBAN\"] = pd.to_numeric(noro_station[\"WBAN\"], errors='coerce').fillna('0').astype('int32')\n",
    "for a in range(len(noro_station)):\n",
    "    wban_unmodified = noro_station.loc[a, \"WBAN\"]\n",
    "    if 0 < wban_unmodified < 10000: \n",
    "        noro_station.loc[a, \"WBAN\"] = str(wban_unmodified).zfill(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de73fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "noro_null = pd.read_csv('/Users/evelyn/Desktop/weather information/noro_interpolated stations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65a6ed85",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(noro_null)):\n\u001b[1;32m      2\u001b[0m     noro_null\u001b[38;5;241m.\u001b[39mloc[z, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSAF0\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(noro_null\u001b[38;5;241m.\u001b[39mloc[z, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSAF0\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m     noro_null\u001b[38;5;241m.\u001b[39mloc[z, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWBAN0\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnoro_null\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWBAN0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(pd\u001b[38;5;241m.\u001b[39misna(noro_null\u001b[38;5;241m.\u001b[39mloc[z, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSAF1\u001b[39m\u001b[38;5;124m\"\u001b[39m])):\n\u001b[1;32m      6\u001b[0m         noro_null\u001b[38;5;241m.\u001b[39mloc[z, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSAF1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(noro_null\u001b[38;5;241m.\u001b[39mloc[z, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSAF1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "for z in range(len(noro_null)):\n",
    "    noro_null.loc[z, \"USAF0\"] = str(noro_null.loc[z, \"USAF0\"])\n",
    "    noro_null.loc[z, \"WBAN0\"] = str(int(noro_null.loc[z, \"WBAN0\"]))\n",
    "    \n",
    "    if not(pd.isna(noro_null.loc[z, \"USAF1\"])):\n",
    "        noro_null.loc[z, \"USAF1\"] = str(noro_null.loc[z, \"USAF1\"])\n",
    "        noro_null.loc[z, \"WBAN1\"] = str(int(noro_null.loc[z, \"WBAN1\"]))\n",
    "        \n",
    "    if not(pd.isna(noro_null.loc[z, \"USAF2\"])):\n",
    "        noro_null.loc[z, \"USAF2\"] = str(noro_null.loc[z, \"USAF2\"])\n",
    "        noro_null.loc[z, \"WBAN2\"] = str(int(noro_null.loc[z, \"WBAN2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "31a548a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000%\n",
      "0.0401%\n",
      "0.0803%\n",
      "0.1204%\n",
      "0.1605%\n",
      "0.2006%\n",
      "0.2408%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2809%\n",
      "0.3210%\n",
      "0.3612%\n",
      "0.4013%\n",
      "0.4414%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4815%\n",
      "0.5217%\n",
      "0.5618%\n",
      "0.6019%\n",
      "0.6421%\n",
      "0.6822%\n",
      "0.7223%\n",
      "0.7624%\n",
      "0.8026%\n",
      "0.8427%\n",
      "0.8828%\n",
      "0.9230%\n",
      "0.9631%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0032%\n",
      "1.0433%\n",
      "1.0835%\n",
      "1.1236%\n",
      "1.1637%\n",
      "1.2039%\n",
      "1.2440%\n",
      "1.2841%\n",
      "1.3242%\n",
      "1.3644%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4045%\n",
      "1.4446%\n",
      "1.4848%\n",
      "1.5249%\n",
      "1.5650%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6051%\n",
      "1.6453%\n",
      "1.6854%\n",
      "1.7255%\n",
      "1.7657%\n",
      "1.8058%\n",
      "1.8459%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8860%\n",
      "1.9262%\n",
      "1.9663%\n",
      "2.0064%\n",
      "2.0465%\n",
      "2.0867%\n",
      "2.1268%\n",
      "2.1669%\n",
      "2.2071%\n",
      "2.2472%\n",
      "2.2873%\n",
      "2.3274%\n",
      "2.3676%\n",
      "2.4077%\n",
      "2.4478%\n",
      "2.4880%\n",
      "2.5281%\n",
      "2.5682%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6083%\n",
      "2.6485%\n",
      "2.6886%\n",
      "2.7287%\n",
      "2.7689%\n",
      "2.8090%\n",
      "2.8491%\n",
      "2.8892%\n",
      "2.9294%\n",
      "2.9695%\n",
      "3.0096%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0498%\n",
      "3.0899%\n",
      "3.1300%\n",
      "3.1701%\n",
      "3.2103%\n",
      "3.2504%\n",
      "3.2905%\n",
      "3.3307%\n",
      "3.3708%\n",
      "3.4109%\n",
      "3.4510%\n",
      "3.4912%\n",
      "3.5313%\n",
      "3.5714%\n",
      "3.6116%\n",
      "3.6517%\n",
      "3.6918%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7319%\n",
      "3.7721%\n",
      "3.8122%\n",
      "3.8523%\n",
      "3.8925%\n",
      "3.9326%\n",
      "3.9727%\n",
      "4.0128%\n",
      "4.0530%\n",
      "4.0931%\n",
      "4.1332%\n",
      "4.1734%\n",
      "4.2135%\n",
      "4.2536%\n",
      "4.2937%\n",
      "4.3339%\n",
      "4.3740%\n",
      "4.4141%\n",
      "4.4543%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/evelyn/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4944%\n",
      "4.5345%\n",
      "4.5746%\n",
      "4.6148%\n",
      "4.6549%\n",
      "4.6950%\n",
      "4.7352%\n",
      "4.7753%\n",
      "4.8154%\n",
      "4.8555%\n",
      "4.8957%\n",
      "4.9358%\n",
      "4.9759%\n",
      "5.0161%\n",
      "5.0562%\n",
      "5.0963%\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/evelyn/Desktop/weather information/noro_interpolated/72069999999-2010DAILY.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [96]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m wban1 \u001b[38;5;241m=\u001b[39m df_null\u001b[38;5;241m.\u001b[39mloc[k, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWBAN0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     85\u001b[0m filename1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(usaf1) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(wban1) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(yr) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDAILY.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 86\u001b[0m dfn \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilename1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(dfn\u001b[38;5;241m.\u001b[39mDATE\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;28mstr\u001b[39m(d)[:\u001b[38;5;241m10\u001b[39m])\u001b[38;5;241m.\u001b[39many()):\n\u001b[1;32m     88\u001b[0m     a \u001b[38;5;241m=\u001b[39m dfn[dfn\u001b[38;5;241m.\u001b[39mDATE \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m(d)[:\u001b[38;5;241m10\u001b[39m]]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/evelyn/Desktop/weather information/noro_interpolated/72069999999-2010DAILY.csv'"
     ]
    }
   ],
   "source": [
    "path = '/Users/evelyn/Desktop/weather information/noro-weather/'\n",
    "\n",
    "path1 = '/Users/evelyn/Desktop/weather information/noro_interpolated/'\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for i in range(len(noro)):\n",
    "    print('{:.4%}'.format(i/len(noro)))\n",
    "    \n",
    "    df_outbreak = noro_station[noro_station[\"CDCID\"] == noro.loc[i,\"CDCID\"]]\n",
    "    df_outbreak = df_outbreak.reset_index(drop = True)\n",
    "    \n",
    "    df_null = noro_null[noro_null[\"CDCID\"] == noro.loc[i,\"CDCID\"]]\n",
    "    df_null = df_null.reset_index(drop = True)\n",
    "    \n",
    "    TEMP = [] ; MAX = [] ; MIN = [] ; DEWP = [] ; SLP = [] ; STP = [] ; WDSP = [] ; MXSPD = [];\n",
    "    PRCP = [] ; SNDP = [];\n",
    "    Fog = [] ; Rain = [] ; Snow = [] ; Hail = [] ; Thunder = [] ; Tornado = [];\n",
    "    if (len(df_outbreak) > 0):\n",
    "        startdate = datetime.datetime.strptime(df_outbreak.loc[0, \"InitialExposure\"], \"%Y-%m-%d\")\n",
    "        enddate = datetime.datetime.strptime(df_outbreak.loc[0, \"LastExposure\"], \"%Y-%m-%d\")\n",
    "    elif (len(df_null) > 0):\n",
    "        startdate = datetime.datetime.strptime(df_null.loc[0, \"InitialExposure\"], \"%Y-%m-%d\")\n",
    "        enddate = datetime.datetime.strptime(df_null.loc[0, \"LastExposure\"], \"%Y-%m-%d\")\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    delta = datetime.timedelta(days=1)\n",
    "    d = startdate\n",
    "    \n",
    "    while d <= enddate:\n",
    "        yr = int(str(d)[:4])\n",
    "        TEMP1 = [] ; MAX1 = [] ; MIN1 = [] ; DEWP1 = [] ; SLP1 = [] ; STP1 = [] ; WDSP1 = [] ; MXSPD1 = [];\n",
    "        PRCP1 = [] ; SNDP1 = [];\n",
    "        Fog1 = [] ; Rain1 = [] ; Snow1 = [] ; Hail1 = [] ; Thunder1 = [] ; Tornado1 = [];\n",
    "        \n",
    "        if (len(df_outbreak) > 0):\n",
    "            for j in range(len(df_outbreak)):\n",
    "                usaf = df_outbreak.loc[j, \"USAF\"]\n",
    "                wban = df_outbreak.loc[j, \"WBAN\"]\n",
    "                filename = str(usaf) + str(wban) + \"-\" + str(yr) + \"DAILY.csv\"\n",
    "                if not(os.path.isfile(path+filename)):\n",
    "                    continue \n",
    "                elif(sum(1 for line in open(path+filename)) < 10):\n",
    "                    continue \n",
    "                else:\n",
    "                    df = pd.read_csv(path + filename)\n",
    "                    if(df.DATE.str.contains(str(d)[:10]).any()):\n",
    "                        m = df[df.DATE == str(d)[:10]].index.tolist()[0]\n",
    "                        if(df.loc[m, \"TEMP\"] < 9999):\n",
    "                            TEMP1.append(df.loc[m, \"TEMP\"])\n",
    "                        if(df.loc[m, \"MAX\"] < 9999):\n",
    "                            MAX1.append(df.loc[m, \"MAX\"])\n",
    "                        if(df.loc[m, \"MIN\"] < 9999):\n",
    "                            MIN1.append(df.loc[m, \"MIN\"])\n",
    "                        if(df.loc[m, \"DEWP\"] < 9999):\n",
    "                            DEWP1.append(df.loc[m, \"DEWP\"])\n",
    "                        if(df.loc[m, \"SLP\"] < 9999):\n",
    "                            SLP1.append(df.loc[m, \"SLP\"])\n",
    "                        if(df.loc[m, \"STP\"] < 9999):\n",
    "                            STP1.append(df.loc[m, \"STP\"])\n",
    "                        if(df.loc[m, \"WDSP\"] < 999):\n",
    "                            WDSP1.append(df.loc[m, \"WDSP\"])\n",
    "                        if(df.loc[m, \"MXSPD\"] < 998):\n",
    "                            MXSPD1.append(df.loc[m, \"MXSPD\"])\n",
    "                        if(df.loc[m, \"PRCP\"] < 99):\n",
    "                            PRCP1.append(df.loc[m, \"PRCP\"])\n",
    "\n",
    "                        SNDP1.append(df.loc[m, \"SNDP\"]) \n",
    "                        Fog1.append(df.loc[m, \"Fog\"])\n",
    "                        Rain1.append(df.loc[m, \"Rain or Drizzle\"])\n",
    "                        Snow1.append(df.loc[m, \"Snow or Ice Pellets\"])\n",
    "                        Hail1.append(df.loc[m, \"Hail\"])\n",
    "                        Thunder1.append(df.loc[m, \"Thunder\"])\n",
    "                        Tornado1.append(df.loc[m, \"Tornado or Funnel Cloud\"])\n",
    "                    else:\n",
    "                        continue\n",
    "        if (len(df_null) > 0):\n",
    "            for k in range(len(df_null)):\n",
    "                usaf1 = df_null.loc[k, \"USAF0\"]\n",
    "                wban1 = df_null.loc[k, \"WBAN0\"]\n",
    "                filename1 = str(usaf1) + str(wban1) + \"-\" + str(yr) + \"DAILY.csv\"\n",
    "                dfn = pd.read_csv(path1 + filename1)\n",
    "                if(dfn.DATE.str.contains(str(d)[:10]).any()):\n",
    "                    a = dfn[dfn.DATE == str(d)[:10]].index.tolist()[0]\n",
    "                    if(dfn.loc[a, \"TEMP\"] < 9999):\n",
    "                        TEMP1.append(dfn.loc[a, \"TEMP\"]) \n",
    "                    if(dfn.loc[a, \"MAX\"] < 9999):\n",
    "                        MAX1.append(dfn.loc[a, \"MAX\"])\n",
    "                    if(dfn.loc[a, \"MIN\"] < 9999):\n",
    "                        MIN1.append(dfn.loc[a, \"MIN\"])\n",
    "                    if(dfn.loc[a, \"DEWP\"] < 9999):\n",
    "                        DEWP1.append(dfn.loc[a, \"DEWP\"])\n",
    "                    if(dfn.loc[a, \"SLP\"] < 9999):\n",
    "                        SLP1.append(dfn.loc[a, \"SLP\"])\n",
    "                    if(dfn.loc[a, \"STP\"] < 9999):\n",
    "                        STP1.append(dfn.loc[a, \"STP\"])\n",
    "                    if(dfn.loc[a, \"WDSP\"] < 999):\n",
    "                        WDSP1.append(dfn.loc[a, \"WDSP\"])\n",
    "                    if(dfn.loc[a, \"MXSPD\"] < 998):\n",
    "                        MXSPD1.append(dfn.loc[a, \"MXSPD\"])\n",
    "                    if(dfn.loc[a, \"PRCP\"] < 99):\n",
    "                        PRCP1.append(dfn.loc[a, \"PRCP\"])\n",
    "                        \n",
    "                    SNDP1.append(dfn.loc[a, \"SNDP\"])\n",
    "                    Fog1.append(dfn.loc[a, \"Fog\"])\n",
    "                    Rain1.append(dfn.loc[a, \"Rain or Drizzle\"])\n",
    "                    Snow1.append(dfn.loc[a, \"Snow or Ice Pellets\"])\n",
    "                    Hail1.append(dfn.loc[a, \"Hail\"])\n",
    "                    Thunder1.append(dfn.loc[a, \"Thunder\"])\n",
    "                    Tornado1.append(dfn.loc[a, \"Tornado or Funnel Cloud\"])\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "        if not(len(TEMP1) == 0):\n",
    "            TEMP.append(np.mean(TEMP1))\n",
    "        if not(len(MAX1) == 0):\n",
    "            MAX.append(np.mean(MAX1))\n",
    "        if not (len(MIN1) == 0):\n",
    "            MIN.append(np.mean(MIN1))\n",
    "        if not (len(DEWP1) == 0):\n",
    "            DEWP.append(np.mean(DEWP1))\n",
    "        if not (len(SLP1) == 0):\n",
    "            SLP.append(np.mean(SLP1))\n",
    "        if not (len(STP1) == 0):\n",
    "            STP.append(np.mean(STP1))\n",
    "        if not (len(WDSP1) == 0):\n",
    "            WDSP.append(np.mean(WDSP1))\n",
    "        if not (len(MXSPD1) == 0):\n",
    "            MXSPD.append(np.mean(MXSPD1))\n",
    "        if not (len(PRCP1) == 0):\n",
    "            PRCP.append(np.mean(PRCP1))\n",
    "        if not (len(SNDP1) == 0):\n",
    "            SNDP.append(np.mean(SNDP1))\n",
    "        if not (len(Fog1) == 0):\n",
    "            Fog.append(np.mean(Fog1))\n",
    "        if not (len(Rain1) == 0):\n",
    "            Rain.append(np.mean(Rain1))\n",
    "        if not (len(Snow1) == 0):\n",
    "            Snow.append(np.mean(Snow1))\n",
    "        if not (len(Hail1) == 0):\n",
    "            Hail.append(np.mean(Hail1))\n",
    "        if not (len(Thunder1) == 0):\n",
    "            Thunder.append(np.mean(Thunder1))\n",
    "        if not (len(Tornado1) == 0):\n",
    "            Tornado.append(np.mean(Tornado1))\n",
    "        \n",
    "        d = d + delta\n",
    "        \n",
    "    noro.loc[i, \"TEMP\"] = np.mean(TEMP); \n",
    "    noro.loc[i, \"MAX\"] = np.mean(MAX); \n",
    "    noro.loc[i, \"MIN\"] = np.mean(MIN);\n",
    "    noro.loc[i, \"DEWP\"] = np.mean(DEWP); \n",
    "    noro.loc[i, \"SLP\"] = np.mean(SLP); \n",
    "    noro.loc[i, \"STP\"] = np.mean(STP);\n",
    "    noro.loc[i, \"WDSP\"] = np.mean(WDSP); \n",
    "    noro.loc[i, \"MXSPD\"] = np.mean(MXSPD); \n",
    "    noro.loc[i, \"PRCP\"] = np.mean(PRCP);\n",
    "    noro.loc[i, \"SNDP\"] = np.mean(SNDP); \n",
    "    noro.loc[i, \"Fog\"] = np.mean(Fog); \n",
    "    noro.loc[i, \"Rain or Drizzle\"] = np.mean(Rain);\n",
    "    noro.loc[i, \"Snow or Ice Pellets\"] = np.mean(Snow); \n",
    "    noro.loc[i, \"Hail\"] = np.mean(Hail); \n",
    "    noro.loc[i, \"Thunder\"] = np.mean(Thunder); \n",
    "    noro.loc[i, \"Tornado or Funnel Cloud\"] = np.mean(Tornado);  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7897ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "noro = pd.read_csv('/Users/evelyn/Desktop/noro1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "996c193c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CDCID                         0\n",
       "GenusName                     0\n",
       "InitialExposure               0\n",
       "LastExposure                  0\n",
       "TotalCases                    0\n",
       "Exposurestate                 0\n",
       "ExposureState                 0\n",
       "ExposureCounty1               0\n",
       "ExposureCounty2            2463\n",
       "ExposureCounty3            2478\n",
       "ExposureCounty4            2485\n",
       "ExposureCounty5            2487\n",
       "ExposureCounty6            2489\n",
       "ExposureCounty7            2491\n",
       "ExposureCounty8            2492\n",
       "ExposureCounty9            2492\n",
       "ExposureCounty10           2492\n",
       "ExposureCounty11           2492\n",
       "TEMP                         25\n",
       "MAX                          25\n",
       "MIN                          25\n",
       "DEWP                         56\n",
       "SLP                         358\n",
       "STP                          25\n",
       "WDSP                         32\n",
       "MXSPD                        33\n",
       "PRCP                         70\n",
       "SNDP                         25\n",
       "Fog                          25\n",
       "Rain or Drizzle              25\n",
       "Snow or Ice Pellets          25\n",
       "Hail                         25\n",
       "Thunder                      25\n",
       "Tornado or Funnel Cloud      25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noro.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "25e2efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [16626, 276953] #have direct usaf and wban but failed to capture data during outbreaks\n",
    "c = [3324, 7043, 12383, 14489, 14536, 16624, 267137, 267497, 267844, 268046, 269273, 269722, 270729, 284436, 287141, 293420, 295765, 298887]\n",
    "path = '/Users/evelyn/Desktop/project/noro_null/'\n",
    "for i in range(len(c)):\n",
    "    TEMP2 = [] ; MAX2 = [] ; MIN2 = [] ; DEWP2 = [] ; SLP2 = [] ; STP2 = [] ; WDSP2 = [] ; MXSPD2 = [];\n",
    "    PRCP2 = [] ; SNDP2= [];\n",
    "    Fog2 = [] ; Rain2 = [] ; Snow2 = [] ; Hail2 = [] ; Thunder2 = [] ; Tornado2 = [];\n",
    "    index = noro[noro.CDCID == c[i]].index.tolist()[0]\n",
    "    k = noro_null[noro_null.CDCID == c[i]].index.tolist()[0]\n",
    "    \n",
    "    startdate = datetime.datetime.strptime(noro_null.loc[k, \"InitialExposure\"], \"%Y-%m-%d\")\n",
    "    enddate = datetime.datetime.strptime(noro_null.loc[k, \"LastExposure\"], \"%Y-%m-%d\")\n",
    "    d = startdate\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    \n",
    "    \n",
    "    while d <= enddate:\n",
    "        yr = int(str(d)[:4])\n",
    "        w = [noro_null.loc[k, \"W0\"], noro_null.loc[k,\"W1\"], noro_null.loc[k,\"W2\"]]\n",
    "        \n",
    "        usaf0 = noro_null.loc[k, \"USAF0\"]\n",
    "        wban0 = noro_null.loc[k, \"WBAN0\"]\n",
    "        filename0 = str(usaf0) + str(wban0) + \"-\" + str(yr) + \"DAILY.csv\"\n",
    "        df0 = pd.read_csv(path + filename0)\n",
    "\n",
    "        usaf1 = noro_null.loc[k, \"USAF1\"]\n",
    "        wban1 = noro_null.loc[k, \"WBAN1\"]\n",
    "        filename1 = str(usaf1) + str(wban1) + \"-\" + str(yr) + \"DAILY.csv\"\n",
    "        df1 = pd.read_csv(path + filename1)\n",
    "        \n",
    "        if not(pd.isna(noro_null.loc[k,\"USAF2\"])):\n",
    "            usaf2 = noro_null.loc[k, \"USAF2\"]\n",
    "            wban2 = noro_null.loc[k, \"WBAN2\"]\n",
    "            filename2 = str(usaf2) + str(wban2) + \"-\" + str(yr) + \"DAILY.csv\"\n",
    "            df2 = pd.read_csv(path + filename2)\n",
    "        \n",
    "        TEMP3 = [] ; MAX3 = [] ; MIN3 = [] ; DEWP3 = [] ; SLP3 = [] ; STP3 = [] ; WDSP3 = [] ; MXSPD3 = [];\n",
    "        PRCP3 = [] ; SNDP3 = [];\n",
    "        Fog3 = [] ; Rain3 = [] ; Snow3 = [] ; Hail3 = [] ; Thunder3 = [] ; Tornado3 = [];\n",
    "        w1 = w\n",
    "        w2 = w\n",
    "        w3 = w\n",
    "        w4 = w\n",
    "        w5 = w\n",
    "        w6 = w\n",
    "        w7 = w\n",
    "        w8 = w\n",
    "        w9 = w\n",
    "        if(df0.DATE.str.contains(str(d)[:10]).any()):\n",
    "            e = df0[df0.DATE == str(d)[:10]].index.tolist()[0]\n",
    "            if(df0.loc[e, \"TEMP\"] < 9999):\n",
    "                TEMP3.append(df0.loc[e, \"TEMP\"]) \n",
    "            else:\n",
    "                w1[0] = 0\n",
    "            if(df0.loc[e, \"MAX\"] < 9999):\n",
    "                MAX3.append(df0.loc[e, \"MAX\"])\n",
    "            else:\n",
    "                w2[0] = 0\n",
    "            if(df0.loc[e, \"MIN\"] < 9999):\n",
    "                MIN3.append(df0.loc[e, \"MIN\"])\n",
    "            else:\n",
    "                w3[0] = 0\n",
    "            if(df0.loc[e, \"DEWP\"] < 9999):\n",
    "                DEWP3.append(df0.loc[e, \"DEWP\"])\n",
    "            else:\n",
    "                w4[0] = 0\n",
    "            if(df0.loc[e, \"SLP\"] < 9999):\n",
    "                SLP3.append(df0.loc[e, \"SLP\"])\n",
    "            else:\n",
    "                w5[0] = 0\n",
    "            if(df0.loc[e, \"STP\"] < 9999):\n",
    "                STP3.append(df0.loc[e, \"STP\"])\n",
    "            else:\n",
    "                w6[0] = 0\n",
    "            if(df0.loc[e, \"WDSP\"] < 999):\n",
    "                WDSP3.append(df0.loc[e, \"WDSP\"])\n",
    "            else:\n",
    "                w7[0] = 0\n",
    "            if(df0.loc[e, \"MXSPD\"] < 998):\n",
    "                MXSPD3.append(df0.loc[e, \"MXSPD\"])\n",
    "            else:\n",
    "                w8[0] = 0\n",
    "            if(df0.loc[e, \"PRCP\"] < 99):\n",
    "                PRCP3.append(df0.loc[e, \"PRCP\"])\n",
    "            else:\n",
    "                w9[0] = 0\n",
    "            if(df0.loc[e, \"SNDP\"] == 999.9):\n",
    "                SNDP3.append(0)\n",
    "            else:\n",
    "                SNDP3.append(df0.loc[e, \"SNDP\"])\n",
    "            if((df0.loc[e, \"FRSHTT\"]%10) > 0):# 个位\n",
    "                Tornado3.append(int(1))\n",
    "            else:\n",
    "                Tornado3.append(int(0))\n",
    "            if(df0.loc[e, \"FRSHTT\"]//10%10 > 0):#十位\n",
    "                Thunder3.append(int(1))       \n",
    "            else:\n",
    "                Thunder3.append(int(0))       \n",
    "            if((df0.loc[e, \"FRSHTT\"]//100%10) > 0):#百位\n",
    "                Hail3.append(int(1))\n",
    "            else:\n",
    "                Hail3.append(int(0))\n",
    "            if((df0.loc[e, \"FRSHTT\"]//1000%10) > 0):#千位\n",
    "                Snow3.append(int(1))\n",
    "            else:\n",
    "                Snow3.append(int(0))\n",
    "            if((df0.loc[e, \"FRSHTT\"]//10000 % 10) > 0):\n",
    "                Rain3.append(int(1))        \n",
    "            else:\n",
    "                Rain3.append(int(0))\n",
    "            if((df0.loc[e, \"FRSHTT\"]//100000 % 10) > 0):\n",
    "                Fog3.append(int(1))\n",
    "            else:\n",
    "                Fog3.append(int(0))\n",
    "        else:\n",
    "            w[0] = 0\n",
    "        \n",
    " #df1       \n",
    "        if(df1.DATE.str.contains(str(d)[:10]).any()):\n",
    "            a = df1[df1.DATE == str(d)[:10]].index.tolist()[0]\n",
    "            if(df1.loc[a, \"TEMP\"] < 9999):\n",
    "                TEMP3.append(df1.loc[a, \"TEMP\"])\n",
    "            else:\n",
    "                w1[1] = 0\n",
    "            if(df1.loc[a, \"MAX\"] < 9999):\n",
    "                MAX3.append(df1.loc[a, \"MAX\"])\n",
    "            else:\n",
    "                w2[1] = 0\n",
    "            if(df1.loc[a, \"MIN\"] < 9999):\n",
    "                MIN3.append(df1.loc[a, \"MIN\"])\n",
    "            else:\n",
    "                w3[1] = 0\n",
    "            if(df1.loc[a, \"DEWP\"] < 9999):\n",
    "                DEWP3.append(df1.loc[a, \"DEWP\"])\n",
    "            else:\n",
    "                w4[1] = 0\n",
    "            if(df1.loc[a, \"SLP\"] < 9999):\n",
    "                SLP3.append(df1.loc[a, \"SLP\"])\n",
    "            else: \n",
    "                w5[1] = 0\n",
    "            if(df1.loc[a, \"STP\"] < 9999):\n",
    "                STP3.append(df1.loc[a, \"STP\"])\n",
    "            else:\n",
    "                w6[1] = 0\n",
    "            if(df1.loc[a, \"WDSP\"] < 999):\n",
    "                WDSP3.append(df1.loc[a, \"WDSP\"])\n",
    "            else:\n",
    "                w7[1] = 0\n",
    "            if(df1.loc[a, \"MXSPD\"] < 998):\n",
    "                MXSPD3.append(df1.loc[a, \"MXSPD\"])\n",
    "            else:\n",
    "                w8[1] = 0\n",
    "            if(df1.loc[a, \"PRCP\"] < 99):\n",
    "                PRCP3.append(df1.loc[a, \"PRCP\"])\n",
    "            else:\n",
    "                w9[1] = 0\n",
    "            if(df1.loc[a, \"SNDP\"] == 999.9):\n",
    "                SNDP3.append(0)\n",
    "            else:\n",
    "                SNDP3.append(df1.loc[a, \"SNDP\"])\n",
    "            if((df1.loc[a, \"FRSHTT\"]%10) > 0):# 个位\n",
    "                Tornado3.append(int(1))\n",
    "            else:\n",
    "                Tornado3.append(int(0))\n",
    "            if(df1.loc[a, \"FRSHTT\"]//10%10 > 0):#十位\n",
    "                Thunder3.append(int(1))       \n",
    "            else:\n",
    "                Thunder3.append(int(0))       \n",
    "            if((df1.loc[a, \"FRSHTT\"]//100%10) > 0):#百位\n",
    "                Hail3.append(int(1))\n",
    "            else:\n",
    "                Hail3.append(int(0))\n",
    "            if((df1.loc[a, \"FRSHTT\"]//1000%10) > 0):#千位\n",
    "                Snow3.append(int(1))\n",
    "            else:\n",
    "                Snow3.append(int(0))\n",
    "            if((df1.loc[a, \"FRSHTT\"]//10000 % 10) > 0):\n",
    "                Rain3.append(int(1))        \n",
    "            else:\n",
    "                Rain3.append(int(0))\n",
    "            if((df1.loc[a, \"FRSHTT\"]//100000 % 10) > 0):\n",
    "                Fog3.append(int(1))\n",
    "            else:\n",
    "                Fog3.append(int(0))\n",
    "        else:\n",
    "            w[1] = 0\n",
    "#df2    \n",
    "        if not(pd.isna(noro_null.loc[k,\"USAF2\"])):\n",
    "            if(df2.DATE.str.contains(str(d)[:10]).any()):\n",
    "                b = df2[df2.DATE == str(d)[:10]].index.tolist()[0]\n",
    "                if(df2.loc[b, \"TEMP\"] < 9999):\n",
    "                    TEMP3.append(df2.loc[b, \"TEMP\"])\n",
    "                else:\n",
    "                    w1[2] = 0\n",
    "                if(df2.loc[b, \"MAX\"] < 9999):\n",
    "                    MAX3.append(df2.loc[b, \"MAX\"])\n",
    "                else:\n",
    "                    w2[2] = 0\n",
    "                if(df2.loc[b, \"MIN\"] < 9999):\n",
    "                    MIN3.append(df2.loc[b, \"MIN\"])\n",
    "                else:\n",
    "                    w3[2] = 0\n",
    "                if(df2.loc[b, \"DEWP\"] < 9999):\n",
    "                    DEWP3.append(df2.loc[b, \"DEWP\"])\n",
    "                else:\n",
    "                    w4[2] = 0\n",
    "                if(df2.loc[b, \"SLP\"] < 9999):\n",
    "                    SLP3.append(df2.loc[b, \"SLP\"])\n",
    "                else:\n",
    "                    w5[2] = 0\n",
    "                if(df2.loc[b, \"STP\"] < 9999):\n",
    "                    STP3.append(df2.loc[b, \"STP\"])\n",
    "                else:\n",
    "                    w6[2] = 0\n",
    "                if(df2.loc[b, \"WDSP\"] < 999):\n",
    "                    WDSP3.append(df2.loc[b, \"WDSP\"])\n",
    "                else:\n",
    "                    w7[2] = 0\n",
    "                if(df2.loc[b, \"MXSPD\"] < 998):\n",
    "                    MXSPD3.append(df2.loc[b, \"MXSPD\"])\n",
    "                else:\n",
    "                    w8[2] = 0\n",
    "                if(df2.loc[b, \"PRCP\"] < 99):\n",
    "                    PRCP3.append(df2.loc[b, \"PRCP\"])\n",
    "                else:\n",
    "                    w9[2] = 0\n",
    "                if(df2.loc[b, \"SNDP\"] == 999.9):\n",
    "                    SNDP3.append(0)\n",
    "                else:\n",
    "                    SNDP3.append(df2.loc[b, \"SNDP\"])\n",
    "                if((df2.loc[b, \"FRSHTT\"]%10) > 0):# 个位\n",
    "                    Tornado3.append(int(1))\n",
    "                else:\n",
    "                    Tornado3.append(int(0))\n",
    "                if(df2.loc[b, \"FRSHTT\"]//10%10 > 0):#十位\n",
    "                    Thunder3.append(int(1))       \n",
    "                else:\n",
    "                    Thunder3.append(int(0))       \n",
    "                if((df2.loc[b, \"FRSHTT\"]//100%10) > 0):#百位\n",
    "                    Hail3.append(int(1))\n",
    "                else:\n",
    "                    Hail3.append(int(0))\n",
    "                if((df2.loc[b, \"FRSHTT\"]//1000%10) > 0):#千位\n",
    "                    Snow3.append(int(1))\n",
    "                else:\n",
    "                    Snow3.append(int(0))\n",
    "                if((df2.loc[b, \"FRSHTT\"]//10000 % 10) > 0):\n",
    "                    Rain3.append(int(1))        \n",
    "                else:\n",
    "                    Rain3.append(int(0))\n",
    "                if((df2.loc[b, \"FRSHTT\"]//100000 % 10) > 0):\n",
    "                    Fog3.append(int(1))\n",
    "                else:\n",
    "                    Fog3.append(int(0))\n",
    "            else:\n",
    "                w[2] = 0\n",
    "        \n",
    "        for j in range(3):\n",
    "            w[j] = w[j]/(w[0] + w[1] + w[2])\n",
    "            w1[j] = w1[j]/(w1[0] + w1[1] + w1[2])\n",
    "            w2[j] = w2[j]/(w2[0] + w2[1] + w2[2])\n",
    "            w3[j] = w3[j]/(w3[0] + w3[1] + w3[2])\n",
    "            w4[j] = w4[j]/(w4[0] + w4[1] + w4[2])\n",
    "            w5[j] = w5[j]/(w5[0] + w5[1] + w5[2])\n",
    "            w6[j] = w6[j]/(w6[0] + w6[1] + w6[2])\n",
    "            w7[j] = w7[j]/(w7[0] + w7[1] + w7[2])\n",
    "            w8[j] = w8[j]/(w8[0] + w8[1] + w8[2])\n",
    "            w9[j] = w9[j]/(w9[0] + w9[1] + w9[2])\n",
    "        \n",
    "        if 0 in w:\n",
    "            w.remove(0)\n",
    "        if 0 in w1:\n",
    "            w1.remove(0)\n",
    "        if 0 in w2:\n",
    "            w2.remove(0)\n",
    "        if 0 in w3:\n",
    "            w3.remove(0)\n",
    "        if 0 in w4:\n",
    "            w4.remove(0)\n",
    "        if 0 in w5:\n",
    "            w5.remove(0)\n",
    "        if 0 in w6:\n",
    "            w6.remove(0)\n",
    "        if 0 in w7:\n",
    "            w7.remove(0)\n",
    "        if 0 in w8:\n",
    "            w8.remove(0)\n",
    "        if 0 in w9:\n",
    "            w9.remove(0)\n",
    "        \n",
    "        if not(len(TEMP3) == 0):\n",
    "            TEMP2.append(sum(np.multiply(w1, TEMP3)))\n",
    "        if not(len(MAX3) == 0):\n",
    "            MAX2.append(sum(np.multiply(w2, MAX3)))\n",
    "        if not (len(MIN3) == 0):\n",
    "            MIN2.append(sum(np.multiply(w3, MIN3)))\n",
    "        if not (len(DEWP3) == 0):\n",
    "            DEWP2.append(sum(np.multiply(w4, DEWP3)))\n",
    "        if not (len(SLP3) == 0):\n",
    "            SLP2.append(sum(np.multiply(w5, SLP3)))\n",
    "        if not (len(STP3) == 0):\n",
    "            STP2.append(sum(np.multiply(w6,STP3)))\n",
    "        if not (len(WDSP3) == 0):\n",
    "            WDSP2.append(sum(np.multiply(w7, WDSP3)))\n",
    "        if not (len(MXSPD3) == 0):\n",
    "            MXSPD2.append(sum(np.multiply(w8, MXSPD3)))\n",
    "        if not (len(PRCP3) == 0):\n",
    "            PRCP2.append(sum(np.multiply(w9,PRCP3)))\n",
    "        if not (len(SNDP3) == 0):\n",
    "            SNDP2.append(sum(np.multiply(w, SNDP3)))\n",
    "        if not (len(Fog3) == 0):\n",
    "            Fog2.append(sum(np.multiply(w, Fog3)))\n",
    "        if not (len(Rain3) == 0):\n",
    "            Rain2.append(sum(np.multiply(w, Rain3)))\n",
    "        if not (len(Snow3) == 0):\n",
    "            Snow2.append(sum(np.multiply(w, Snow3)))\n",
    "        if not (len(Hail3) == 0):\n",
    "            Hail2.append(sum(np.multiply(w, Hail3)))\n",
    "        if not (len(Thunder3) == 0):\n",
    "            Thunder2.append(sum(np.multiply(w, Thunder3)))\n",
    "        if not (len(Tornado3) == 0):\n",
    "            Tornado2.append(sum(np.multiply(w, Tornado3)))\n",
    "        d = d + delta\n",
    "    \n",
    "    noro.loc[index, \"TEMP\"] = np.mean(TEMP2); \n",
    "    noro.loc[index, \"MAX\"] = np.mean(MAX2); \n",
    "    noro.loc[index, \"MIN\"] = np.mean(MIN2);\n",
    "    noro.loc[index, \"DEWP\"] = np.mean(DEWP2); \n",
    "    noro.loc[index, \"SLP\"] = np.mean(SLP2); \n",
    "    noro.loc[index, \"STP\"] = np.mean(STP2);\n",
    "    noro.loc[index, \"WDSP\"] = np.mean(WDSP2); \n",
    "    noro.loc[index, \"MXSPD\"] = np.mean(MXSPD2); \n",
    "    noro.loc[index, \"PRCP\"] = np.mean(PRCP2);\n",
    "    noro.loc[index, \"SNDP\"] = np.mean(SNDP2); \n",
    "    noro.loc[index, \"Fog\"] = np.mean(Fog2); \n",
    "    noro.loc[index, \"Rain or Drizzle\"] = np.mean(Rain2);\n",
    "    noro.loc[index, \"Snow or Ice Pellets\"] = np.mean(Snow2); \n",
    "    noro.loc[index, \"Hail\"] = np.mean(Hail2); \n",
    "    noro.loc[index, \"Thunder\"] = np.mean(Thunder2); \n",
    "    noro.loc[index, \"Tornado or Funnel Cloud\"] = np.mean(Tornado2); \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd50443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3324, 5379, 7043, 12383, 14489, 14536, 16624, 18483, 267137, 267497, 267816, 267844, 268046, 269208, 269273, 269722, 270729, 284436, 287141, 287693, 287936, 293420, 295765, 298887]\n"
     ]
    }
   ],
   "source": [
    "n = []\n",
    "for i in range(len(noro)):\n",
    "    if(pd.isna(noro.loc[i,\"TEMP\"])):\n",
    "        n.append(noro.loc[i, \"CDCID\"])\n",
    "n.remove(284556)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4a559213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "a.append(noro_null.loc[290,\"W2\"])\n",
    "if 0 in a:\n",
    "    a.remove(0)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a0844909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CDCID                         0\n",
       "GenusName                     0\n",
       "InitialExposure               0\n",
       "LastExposure                  0\n",
       "TotalCases                    0\n",
       "Exposurestate                 0\n",
       "ExposureState                 0\n",
       "ExposureCounty1               0\n",
       "ExposureCounty2            2463\n",
       "ExposureCounty3            2478\n",
       "ExposureCounty4            2485\n",
       "ExposureCounty5            2487\n",
       "ExposureCounty6            2489\n",
       "ExposureCounty7            2491\n",
       "ExposureCounty8            2492\n",
       "ExposureCounty9            2492\n",
       "ExposureCounty10           2492\n",
       "ExposureCounty11           2492\n",
       "TEMP                          5\n",
       "MAX                           5\n",
       "MIN                           5\n",
       "DEWP                         36\n",
       "SLP                         340\n",
       "STP                           5\n",
       "WDSP                         12\n",
       "MXSPD                        13\n",
       "PRCP                         50\n",
       "SNDP                          5\n",
       "Fog                           5\n",
       "Rain or Drizzle               5\n",
       "Snow or Ice Pellets           5\n",
       "Hail                          5\n",
       "Thunder                       5\n",
       "Tornado or Funnel Cloud       5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noro.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a1e1bca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[267816, 269208, 284556, 287693, 287936]\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for i in range(len(noro)):\n",
    "    if(pd.isna(noro.loc[i, \"TEMP\"])):\n",
    "        a.append(noro.loc[i,\"CDCID\"])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "861077aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "noro.to_csv('/Users/evelyn/Desktop/norof.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42676a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt, atan\n",
    "from math import *\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "    R = 3959.87433 #Earth radius in miles\n",
    "    # Convert decimal degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    \n",
    "    a = sin(dlat/2)**2 + sin(dlon/2)**2 * cos(lat1) * cos(lat2)\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    return R*c          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "052db64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_stations = pd.read_csv('/Users/evelyn/Desktop/project/weather-stations.csv', encoding= 'unicode_escape')\n",
    "\n",
    "import heapq\n",
    "import re\n",
    "import os #Import for setting working dirrectory\n",
    "import requests #Import for downloading data from database\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import numpy as np\n",
    "url_base = \"https://www.ncei.noaa.gov/data/global-summary-of-the-day/access/\"\n",
    "weather_stations[\"WBAN\"] = pd.to_numeric(weather_stations[\"WBAN\"], errors='coerce').fillna('0').astype('int32')\n",
    "for z in range(len(weather_stations)):\n",
    "    wban_unmodified = weather_stations.loc[z, \"WBAN\"]\n",
    "    if 0 < wban_unmodified < 10000: \n",
    "        \n",
    "        weather_stations.loc[z, \"WBAN\"] = str(wban_unmodified).zfill(5)\n",
    "        \n",
    "i = 292\n",
    "slat = float(noro_null.loc[i, \"LAT\"])\n",
    "slon = float(noro_null.loc[i, \"LON\"])\n",
    "for j in range(len(weather_stations)):\n",
    "    lat = float(weather_stations.loc[j, \"LAT\"])\n",
    "    lon = float(weather_stations.loc[j, \"LON\"])\n",
    "    weather_stations.loc[j, \"DIS\"] = haversine(slat, slon, lat, lon)\n",
    "dis = weather_stations[\"DIS\"].tolist()\n",
    "\n",
    "weather_stations[\"WBAN\"] = pd.to_numeric(weather_stations[\"WBAN\"], errors='coerce').astype('int32')\n",
    "for l in range(60):\n",
    "    z = []\n",
    "    min_index = list(map(dis.index, heapq.nsmallest(3, dis)))\n",
    "    dlat = [weather_stations.loc[min_index[0], \"LAT\"], weather_stations.loc[min_index[1], \"LAT\"], weather_stations.loc[min_index[2],\"LAT\"]]\n",
    "    dlon = [weather_stations.loc[min_index[0], \"LON\"], weather_stations.loc[min_index[1], \"LON\"], weather_stations.loc[min_index[2],\"LON\"]]\n",
    "    if(min(dlat) < slat and slat < max(dlat) and min(dlon) < slon and slon < max(dlon)):\n",
    "        for m in range(3):\n",
    "            usaf = weather_stations.loc[min_index[m], \"USAF\"]\n",
    "            #print(usaf) \n",
    "            wban = weather_stations.loc[min_index[m], \"WBAN\"]\n",
    "            #print(wban)\n",
    "            startyear = str(noro_null.loc[i , \"InitialExposure\"])[:4] #Extracts the year from the date string by taking the first four elements\n",
    "            #print(startyear)\n",
    "            endyear = str(noro_null.loc[i , \"LastExposure\"])[:4]  \n",
    "            #print(endyear)\n",
    "            filename_noaa = str(usaf) + str(wban) + \".csv\" \n",
    "            for yr in range(int(startyear), int(endyear)+1): \n",
    "                url_loop_daily = url_base + str(yr) + \"/\" + filename_noaa\n",
    "                #print(url_loop_daily)\n",
    "\n",
    "                #Identifies file on website\n",
    "                csv_current_daily = requests.get(url_loop_daily, allow_redirects = True)\n",
    "\n",
    "                #Sets the file name of the local imported file\n",
    "                filename_local_daily =  str(usaf) + str(wban) + \"-\" + str(yr) + \"DAILY.csv\" \n",
    "                os.chdir('/Users/evelyn/Desktop/project/noro_null') #Sets path for daily data csv deposit  \n",
    "                open(filename_local_daily, \"wb\").write(csv_current_daily.content) #Write a csv for daily data\n",
    "                total = sum(1 for line in open(filename_local_daily))\n",
    "                if(total < 30):\n",
    "                    dis[min_index[m]] = 100\n",
    "                    z.append(100)\n",
    "                else:\n",
    "                    z.append(0)\n",
    "        if(max(z) < 50):\n",
    "            break\n",
    "        else: \n",
    "            continue\n",
    "    else:\n",
    "        dis[min_index[2]] = 100\n",
    "\n",
    "for k in range(3):\n",
    "    index = min_index[k]\n",
    "    noro_null.loc[i, \"USAF\"+str(k)] = weather_stations.loc[index, \"USAF\"]\n",
    "    noro_null.loc[i, \"WBAN\"+str(k)] = weather_stations.loc[index, \"WBAN\"]\n",
    "    noro_null.loc[i, \"DIS\"+str(k)] = dis[index]\n",
    "noro_null.loc[i, \"W0\"] = 1/(1/noro_null.loc[i, \"DIS0\"] + 1/noro_null.loc[i, \"DIS1\"] + 1/noro_null.loc[i, \"DIS2\"])/1/noro_null.loc[i, \"DIS0\"]\n",
    "noro_null.loc[i, \"W1\"] = 1/(1/noro_null.loc[i, \"DIS0\"] + 1/noro_null.loc[i, \"DIS1\"] + 1/noro_null.loc[i, \"DIS2\"])/1/noro_null.loc[i, \"DIS1\"]\n",
    "noro_null.loc[i, \"W2\"] = 1/(1/noro_null.loc[i, \"DIS0\"] + 1/noro_null.loc[i, \"DIS1\"] + 1/noro_null.loc[i, \"DIS2\"])/1/noro_null.loc[i, \"DIS2\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5d291a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDCID</th>\n",
       "      <th>GenusName</th>\n",
       "      <th>InitialExposure</th>\n",
       "      <th>LastExposure</th>\n",
       "      <th>TotalCases</th>\n",
       "      <th>Exposurestate</th>\n",
       "      <th>ExposureState</th>\n",
       "      <th>County</th>\n",
       "      <th>County1</th>\n",
       "      <th>LAT</th>\n",
       "      <th>...</th>\n",
       "      <th>DIS0</th>\n",
       "      <th>USAF1</th>\n",
       "      <th>WBAN1</th>\n",
       "      <th>DIS1</th>\n",
       "      <th>USAF2</th>\n",
       "      <th>WBAN2</th>\n",
       "      <th>DIS2</th>\n",
       "      <th>W0</th>\n",
       "      <th>W1</th>\n",
       "      <th>W2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>6</td>\n",
       "      <td>IL</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>McHenry</td>\n",
       "      <td>McHenry County</td>\n",
       "      <td>42.324298</td>\n",
       "      <td>...</td>\n",
       "      <td>30.879758</td>\n",
       "      <td>725430</td>\n",
       "      <td>94822</td>\n",
       "      <td>34.008514</td>\n",
       "      <td>726415</td>\n",
       "      <td>94854</td>\n",
       "      <td>35.857541</td>\n",
       "      <td>0.361118</td>\n",
       "      <td>0.327895</td>\n",
       "      <td>0.310987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>2009-03-05</td>\n",
       "      <td>2009-03-07</td>\n",
       "      <td>9</td>\n",
       "      <td>TN</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Bradley</td>\n",
       "      <td>Bradley County</td>\n",
       "      <td>35.153914</td>\n",
       "      <td>...</td>\n",
       "      <td>20.967150</td>\n",
       "      <td>722154</td>\n",
       "      <td>53885</td>\n",
       "      <td>29.855746</td>\n",
       "      <td>722177</td>\n",
       "      <td>63811</td>\n",
       "      <td>56.248877</td>\n",
       "      <td>0.481919</td>\n",
       "      <td>0.338443</td>\n",
       "      <td>0.179638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>2009-05-31</td>\n",
       "      <td>2009-05-31</td>\n",
       "      <td>15</td>\n",
       "      <td>OH</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Medina</td>\n",
       "      <td>Medina County</td>\n",
       "      <td>41.116174</td>\n",
       "      <td>...</td>\n",
       "      <td>20.183821</td>\n",
       "      <td>724303</td>\n",
       "      <td>14813</td>\n",
       "      <td>23.403818</td>\n",
       "      <td>998179</td>\n",
       "      <td>99999</td>\n",
       "      <td>36.233294</td>\n",
       "      <td>0.413314</td>\n",
       "      <td>0.356449</td>\n",
       "      <td>0.230237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2465</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>2009-07-13</td>\n",
       "      <td>2009-07-13</td>\n",
       "      <td>31</td>\n",
       "      <td>NH</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Sullivan</td>\n",
       "      <td>Sullivan County</td>\n",
       "      <td>43.361188</td>\n",
       "      <td>...</td>\n",
       "      <td>15.080658</td>\n",
       "      <td>726116</td>\n",
       "      <td>94765</td>\n",
       "      <td>18.835519</td>\n",
       "      <td>742078</td>\n",
       "      <td>64773</td>\n",
       "      <td>37.191558</td>\n",
       "      <td>0.453281</td>\n",
       "      <td>0.362920</td>\n",
       "      <td>0.183799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2340</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>2009-06-20</td>\n",
       "      <td>2009-06-20</td>\n",
       "      <td>13</td>\n",
       "      <td>KS</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>Franklin County</td>\n",
       "      <td>38.558019</td>\n",
       "      <td>...</td>\n",
       "      <td>27.805225</td>\n",
       "      <td>724565</td>\n",
       "      <td>13920</td>\n",
       "      <td>33.207241</td>\n",
       "      <td>724556</td>\n",
       "      <td>13989</td>\n",
       "      <td>52.050431</td>\n",
       "      <td>0.421670</td>\n",
       "      <td>0.353075</td>\n",
       "      <td>0.225255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>267816</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>2016-02-26</td>\n",
       "      <td>2016-02-26</td>\n",
       "      <td>5</td>\n",
       "      <td>FL</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Flagler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.474891</td>\n",
       "      <td>...</td>\n",
       "      <td>33.613320</td>\n",
       "      <td>722361</td>\n",
       "      <td>92808</td>\n",
       "      <td>35.525765</td>\n",
       "      <td>722057</td>\n",
       "      <td>12854</td>\n",
       "      <td>48.093592</td>\n",
       "      <td>0.378060</td>\n",
       "      <td>0.357708</td>\n",
       "      <td>0.264232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>267844</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>2016-03-13</td>\n",
       "      <td>31</td>\n",
       "      <td>TN</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Knox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.992726</td>\n",
       "      <td>...</td>\n",
       "      <td>4.079523</td>\n",
       "      <td>723260</td>\n",
       "      <td>13891</td>\n",
       "      <td>12.374558</td>\n",
       "      <td>724270</td>\n",
       "      <td>53868</td>\n",
       "      <td>16.695950</td>\n",
       "      <td>0.635319</td>\n",
       "      <td>0.209446</td>\n",
       "      <td>0.155235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>269208</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>2016-06-08</td>\n",
       "      <td>2016-06-08</td>\n",
       "      <td>23</td>\n",
       "      <td>FL</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Sarasota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.225327</td>\n",
       "      <td>...</td>\n",
       "      <td>54.720145</td>\n",
       "      <td>720373</td>\n",
       "      <td>92824</td>\n",
       "      <td>55.852326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.505120</td>\n",
       "      <td>0.494880</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>287936</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>2019-05-26</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>5</td>\n",
       "      <td>MN</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Rice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.350775</td>\n",
       "      <td>...</td>\n",
       "      <td>1.531065</td>\n",
       "      <td>722003</td>\n",
       "      <td>54930</td>\n",
       "      <td>16.414133</td>\n",
       "      <td>722032</td>\n",
       "      <td>54916</td>\n",
       "      <td>22.909224</td>\n",
       "      <td>0.861988</td>\n",
       "      <td>0.080404</td>\n",
       "      <td>0.057608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>287141</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>2019-02-16</td>\n",
       "      <td>2019-02-16</td>\n",
       "      <td>7</td>\n",
       "      <td>MD</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>Harford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.537429</td>\n",
       "      <td>...</td>\n",
       "      <td>8.267377</td>\n",
       "      <td>724067</td>\n",
       "      <td>93744</td>\n",
       "      <td>15.451992</td>\n",
       "      <td>724180</td>\n",
       "      <td>13781</td>\n",
       "      <td>38.129475</td>\n",
       "      <td>0.570822</td>\n",
       "      <td>0.305410</td>\n",
       "      <td>0.123768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CDCID  GenusName InitialExposure LastExposure  TotalCases Exposurestate  \\\n",
       "0        46  Norovirus      2009-01-01   2009-01-02           6            IL   \n",
       "1        80  Norovirus      2009-03-05   2009-03-07           9            TN   \n",
       "2      1969  Norovirus      2009-05-31   2009-05-31          15            OH   \n",
       "3      2465  Norovirus      2009-07-13   2009-07-13          31            NH   \n",
       "4      2340  Norovirus      2009-06-20   2009-06-20          13            KS   \n",
       "..      ...        ...             ...          ...         ...           ...   \n",
       "288  267816  Norovirus      2016-02-26   2016-02-26           5            FL   \n",
       "289  267844  Norovirus      2016-03-05   2016-03-13          31            TN   \n",
       "290  269208  Norovirus      2016-06-08   2016-06-08          23            FL   \n",
       "291  287936  Norovirus      2019-05-26   2019-05-27           5            MN   \n",
       "292  287141  Norovirus      2019-02-16   2019-02-16           7            MD   \n",
       "\n",
       "     ExposureState    County          County1        LAT  ...       DIS0  \\\n",
       "0         Illinois   McHenry   McHenry County  42.324298  ...  30.879758   \n",
       "1        Tennessee   Bradley   Bradley County  35.153914  ...  20.967150   \n",
       "2             Ohio    Medina    Medina County  41.116174  ...  20.183821   \n",
       "3    New Hampshire  Sullivan  Sullivan County  43.361188  ...  15.080658   \n",
       "4           Kansas  Franklin  Franklin County  38.558019  ...  27.805225   \n",
       "..             ...       ...              ...        ...  ...        ...   \n",
       "288        Florida   Flagler              NaN  29.474891  ...  33.613320   \n",
       "289      Tennessee      Knox              NaN  35.992726  ...   4.079523   \n",
       "290        Florida  Sarasota              NaN  27.225327  ...  54.720145   \n",
       "291      Minnesota      Rice              NaN  44.350775  ...   1.531065   \n",
       "292       Maryland   Harford              NaN  39.537429  ...   8.267377   \n",
       "\n",
       "      USAF1  WBAN1       DIS1   USAF2  WBAN2       DIS2        W0        W1  \\\n",
       "0    725430  94822  34.008514  726415  94854  35.857541  0.361118  0.327895   \n",
       "1    722154  53885  29.855746  722177  63811  56.248877  0.481919  0.338443   \n",
       "2    724303  14813  23.403818  998179  99999  36.233294  0.413314  0.356449   \n",
       "3    726116  94765  18.835519  742078  64773  37.191558  0.453281  0.362920   \n",
       "4    724565  13920  33.207241  724556  13989  52.050431  0.421670  0.353075   \n",
       "..      ...    ...        ...     ...    ...        ...       ...       ...   \n",
       "288  722361  92808  35.525765  722057  12854  48.093592  0.378060  0.357708   \n",
       "289  723260  13891  12.374558  724270  53868  16.695950  0.635319  0.209446   \n",
       "290  720373  92824  55.852326     NaN    NaN        NaN  0.505120  0.494880   \n",
       "291  722003  54930  16.414133  722032  54916  22.909224  0.861988  0.080404   \n",
       "292  724067  93744  15.451992  724180  13781  38.129475  0.570822  0.305410   \n",
       "\n",
       "           W2  \n",
       "0    0.310987  \n",
       "1    0.179638  \n",
       "2    0.230237  \n",
       "3    0.183799  \n",
       "4    0.225255  \n",
       "..        ...  \n",
       "288  0.264232  \n",
       "289  0.155235  \n",
       "290  0.000000  \n",
       "291  0.057608  \n",
       "292  0.123768  \n",
       "\n",
       "[293 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noro_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e46a9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13701"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noro_null.loc[292, \"WBAN0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f1460a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/Users/evelyn/Desktop/weather information/noro-weather/'\n",
    "f = '74486454787-2016DAILY.csv'\n",
    "pa = '/Users/evelyn/Desktop/'\n",
    "df = pd.read_csv(pa + f)\n",
    "for j in range(len(df)):\n",
    "    if(df.loc[j, \"SNDP\"] > 999):\n",
    "        df.loc[j, \"SNDP\"] = 0\n",
    "    if((df.loc[j, \"FRSHTT\"]%10) > 0):# 个位\n",
    "        df.loc[j, \"Tornado or Funnel Cloud\"] = int(1)\n",
    "    else:\n",
    "        df.loc[j, \"Tornado or Funnel Cloud\"] = int(0)\n",
    "    if(df.loc[j, \"FRSHTT\"]//10%10 > 0):#十位\n",
    "        df.loc[j, \"Thunder\"] = int(1)\n",
    "    else:\n",
    "        df.loc[j, \"Thunder\"] = int(0)\n",
    "    if((df.loc[j, \"FRSHTT\"]//100%10) > 0):#百位\n",
    "        df.loc[j, \"Hail\"] = int(1)\n",
    "    else:\n",
    "        df.loc[j, \"Hail\"] = int(0)\n",
    "    if((df.loc[j, \"FRSHTT\"]//1000%10) > 0):#千位\n",
    "        df.loc[j, \"Snow or Ice Pellets\"] = int(1)\n",
    "    else:\n",
    "        df.loc[j, \"Snow or Ice Pellets\"] = int(0)\n",
    "    if((df.loc[j, \"FRSHTT\"]//10000 % 10) > 0):\n",
    "        df.loc[j, \"Rain or Drizzle\"] = int(1)\n",
    "    else:\n",
    "        df.loc[j, \"Rain or Drizzle\"] = int(0)\n",
    "    if((df.loc[j, \"FRSHTT\"]//100000 % 10) > 0):\n",
    "        df.loc[j, \"Fog\"] = int(1)\n",
    "    else:\n",
    "        df.loc[j, \"Fog\"] = int(0)\n",
    "\n",
    "df.to_csv(p + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "05716c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10010//10%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8a60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70eec2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000%\n",
      "0.3534%\n",
      "0.7067%\n",
      "1.0601%\n",
      "1.4134%\n",
      "1.7668%\n",
      "2.1201%\n",
      "2.4735%\n",
      "2.8269%\n",
      "3.1802%\n",
      "3.5336%\n",
      "3.8869%\n",
      "4.2403%\n",
      "4.5936%\n",
      "4.9470%\n",
      "5.3004%\n",
      "5.6537%\n",
      "6.0071%\n",
      "6.3604%\n",
      "6.7138%\n",
      "7.0671%\n",
      "7.4205%\n",
      "7.7739%\n",
      "8.1272%\n",
      "8.4806%\n",
      "8.8339%\n",
      "9.1873%\n",
      "9.5406%\n",
      "9.8940%\n",
      "10.2473%\n",
      "10.6007%\n",
      "10.9541%\n",
      "11.3074%\n",
      "11.6608%\n",
      "12.0141%\n",
      "12.3675%\n",
      "12.7208%\n",
      "13.0742%\n",
      "13.4276%\n",
      "13.7809%\n",
      "14.1343%\n",
      "14.4876%\n",
      "14.8410%\n",
      "15.1943%\n",
      "15.5477%\n",
      "15.9011%\n",
      "16.2544%\n",
      "16.6078%\n",
      "16.9611%\n",
      "17.3145%\n",
      "17.6678%\n",
      "18.0212%\n",
      "18.3746%\n",
      "18.7279%\n",
      "19.0813%\n",
      "19.4346%\n",
      "19.7880%\n",
      "20.1413%\n",
      "20.4947%\n",
      "20.8481%\n",
      "21.2014%\n",
      "21.5548%\n",
      "21.9081%\n",
      "22.2615%\n",
      "22.6148%\n",
      "22.9682%\n",
      "23.3216%\n",
      "23.6749%\n",
      "24.0283%\n",
      "24.3816%\n",
      "24.7350%\n",
      "25.0883%\n",
      "25.4417%\n",
      "25.7951%\n",
      "26.1484%\n",
      "26.5018%\n",
      "26.8551%\n",
      "27.2085%\n",
      "27.5618%\n",
      "27.9152%\n",
      "28.2686%\n",
      "28.6219%\n",
      "28.9753%\n",
      "29.3286%\n",
      "29.6820%\n",
      "30.0353%\n",
      "30.3887%\n",
      "30.7420%\n",
      "31.0954%\n",
      "31.4488%\n",
      "31.8021%\n",
      "32.1555%\n",
      "32.5088%\n",
      "32.8622%\n",
      "33.2155%\n",
      "33.5689%\n",
      "33.9223%\n",
      "34.2756%\n",
      "34.6290%\n",
      "34.9823%\n",
      "35.3357%\n",
      "35.6890%\n",
      "36.0424%\n",
      "36.3958%\n",
      "36.7491%\n",
      "37.1025%\n",
      "37.4558%\n",
      "37.8092%\n",
      "38.1625%\n",
      "38.5159%\n",
      "38.8693%\n",
      "39.2226%\n",
      "39.5760%\n",
      "39.9293%\n",
      "40.2827%\n",
      "40.6360%\n",
      "40.9894%\n",
      "41.3428%\n",
      "41.6961%\n",
      "42.0495%\n",
      "42.4028%\n",
      "42.7562%\n",
      "43.1095%\n",
      "43.4629%\n",
      "43.8163%\n",
      "44.1696%\n",
      "44.5230%\n",
      "44.8763%\n",
      "45.2297%\n",
      "45.5830%\n",
      "45.9364%\n",
      "46.2898%\n",
      "46.6431%\n",
      "46.9965%\n",
      "47.3498%\n",
      "47.7032%\n",
      "48.0565%\n",
      "48.4099%\n",
      "48.7633%\n",
      "49.1166%\n",
      "49.4700%\n",
      "49.8233%\n",
      "50.1767%\n",
      "50.5300%\n",
      "50.8834%\n",
      "51.2367%\n",
      "51.5901%\n",
      "51.9435%\n",
      "52.2968%\n",
      "52.6502%\n",
      "53.0035%\n",
      "53.3569%\n",
      "53.7102%\n",
      "54.0636%\n",
      "54.4170%\n",
      "54.7703%\n",
      "55.1237%\n",
      "55.4770%\n",
      "55.8304%\n",
      "56.1837%\n",
      "56.5371%\n",
      "56.8905%\n",
      "57.2438%\n",
      "57.5972%\n",
      "57.9505%\n",
      "58.3039%\n",
      "58.6572%\n",
      "59.0106%\n",
      "59.3640%\n",
      "59.7173%\n",
      "60.0707%\n",
      "60.4240%\n",
      "60.7774%\n",
      "61.1307%\n",
      "61.4841%\n",
      "61.8375%\n",
      "62.1908%\n",
      "62.5442%\n",
      "62.8975%\n",
      "63.2509%\n",
      "63.6042%\n",
      "63.9576%\n",
      "64.3110%\n",
      "64.6643%\n",
      "65.0177%\n",
      "65.3710%\n",
      "65.7244%\n",
      "66.0777%\n",
      "66.4311%\n",
      "66.7845%\n",
      "67.1378%\n",
      "67.4912%\n",
      "67.8445%\n",
      "68.1979%\n",
      "68.5512%\n",
      "68.9046%\n",
      "69.2580%\n",
      "69.6113%\n",
      "69.9647%\n",
      "70.3180%\n",
      "70.6714%\n",
      "71.0247%\n",
      "71.3781%\n",
      "71.7314%\n",
      "72.0848%\n",
      "72.4382%\n",
      "72.7915%\n",
      "73.1449%\n",
      "73.4982%\n",
      "73.8516%\n",
      "74.2049%\n",
      "74.5583%\n",
      "74.9117%\n",
      "75.2650%\n",
      "75.6184%\n",
      "75.9717%\n",
      "76.3251%\n",
      "76.6784%\n",
      "77.0318%\n",
      "77.3852%\n",
      "77.7385%\n",
      "78.0919%\n",
      "78.4452%\n",
      "78.7986%\n",
      "79.1519%\n",
      "79.5053%\n",
      "79.8587%\n",
      "80.2120%\n",
      "80.5654%\n",
      "80.9187%\n",
      "81.2721%\n",
      "81.6254%\n",
      "81.9788%\n",
      "82.3322%\n",
      "82.6855%\n",
      "83.0389%\n",
      "83.3922%\n",
      "83.7456%\n",
      "84.0989%\n",
      "84.4523%\n",
      "84.8057%\n",
      "85.1590%\n",
      "85.5124%\n",
      "85.8657%\n",
      "86.2191%\n",
      "86.5724%\n",
      "86.9258%\n",
      "87.2792%\n",
      "87.6325%\n",
      "87.9859%\n",
      "88.3392%\n",
      "88.6926%\n",
      "89.0459%\n",
      "89.3993%\n",
      "89.7527%\n",
      "90.1060%\n",
      "90.4594%\n",
      "90.8127%\n",
      "91.1661%\n",
      "91.5194%\n",
      "91.8728%\n",
      "92.2261%\n",
      "92.5795%\n",
      "92.9329%\n",
      "93.2862%\n",
      "93.6396%\n",
      "93.9929%\n",
      "94.3463%\n",
      "94.6996%\n",
      "95.0530%\n",
      "95.4064%\n",
      "95.7597%\n",
      "96.1131%\n",
      "96.4664%\n",
      "96.8198%\n",
      "97.1731%\n",
      "97.5265%\n",
      "97.8799%\n",
      "98.2332%\n",
      "98.5866%\n",
      "98.9399%\n",
      "99.2933%\n",
      "99.6466%\n"
     ]
    }
   ],
   "source": [
    "#two county intepolate\n",
    "import numpy as np\n",
    "path = '/Users/evelyn/Desktop/project/noro_null/'\n",
    "store_path = '/Users/evelyn/Desktop/noro_fnull/'\n",
    "variable = [\"TEMP\", \"DEWP\", \"SLP\", \"STP\", \"VISIB\", \"WDSP\", \"MXSPD\", \"GUST\", \"MAX\", \"MIN\",\"PRCP\"]\n",
    "for i in range(len(noro_null)):\n",
    "    print('{:.4%}'.format(i/len(noro_null)))\n",
    "    if(pd.isna(noro_null.loc[i, \"USAF2\"])):\n",
    "        file = []\n",
    "        startyear = str(noro_null.loc[i , \"InitialExposure\"])[:4]\n",
    "        endyear = str(noro_null.loc[i , \"LastExposure\"])[:4]\n",
    "        w = [float(noro_null.loc[i, \"W0\"]), float(noro_null.loc[i, \"W1\"])]\n",
    "        for yr in range(int(startyear), int(endyear)+1):\n",
    "            for k in range(2):\n",
    "                usaf = noro_null.loc[i, \"USAF\"+str(k)]\n",
    "                wban = pd.to_numeric(noro_null.loc[i, \"WBAN\"+str(k)]).astype('int32')\n",
    "                filename =  str(usaf) + str(wban) + \"-\" + str(yr) + \"DAILY.csv\" \n",
    "                file.append(filename)\n",
    "            df0 = pd.read_csv(path + file[0])\n",
    "            df1 = pd.read_csv(path + file[1])\n",
    "            for j in range(len(df0)):\n",
    "                date_string = df0.loc[j, \"DATE\"]\n",
    "                if not(df1.DATE.str.contains(date_string).any()):\n",
    "                    df0 = df0.drop(index = [j])\n",
    "            df0 = df0.reset_index(drop = True)\n",
    "            for n in range(len(df0)):\n",
    "                index1 = df1[df1.DATE.str.contains(df0.loc[n, \"DATE\"])].index.tolist()[0]\n",
    "                for vr in range(len(variable)):\n",
    "                    var = [float(df0.loc[n, variable[vr]]), float(df1.loc[index1, variable[vr]])]\n",
    "                    df0.loc[n, variable[vr]] = round(sum(np.multiply(var,w)), 1)\n",
    "                #更改sndp\n",
    "                sndp = [df0.loc[n, \"SNDP\"], df1.loc[index1, \"SNDP\"]]\n",
    "                for sn in range(2):\n",
    "                    if(sndp[sn] > 999):\n",
    "                        sndp[sn] = 0\n",
    "                df0.loc[n, \"SNDP\"] = round(sum(np.multiply(sndp,w)), 1)\n",
    "                #对FRSHTT进行修改\n",
    "                fr = [df0.loc[n, \"FRSHTT\"], df1.loc[index1, \"FRSHTT\"]]\n",
    "                if(((fr[0]%10) + (fr[1]%10)) > 1):# 个位\n",
    "                    df0.loc[n, \"Tornado or Funnel Cloud\"] = int(1)\n",
    "                else:\n",
    "                    df0.loc[n, \"Tornado or Funnel Cloud\"] = int(0)\n",
    "                if(((fr[0]//10%10) + (fr[1]//10%10)) > 1):#十位\n",
    "                    df0.loc[n, \"Thunder\"] = int(1)\n",
    "                else:\n",
    "                    df0.loc[n, \"Thunder\"] = int(0)\n",
    "                if(((fr[0]//100%10) + (fr[1]//100%10)) > 1):#百位\n",
    "                    df0.loc[n, \"Hail\"] = int(1)\n",
    "                else:\n",
    "                    df0.loc[n, \"Hail\"] = int(0)\n",
    "                if(((fr[0]//1000%10) + (fr[1]//1000%10))  > 1):#千位\n",
    "                    df0.loc[n, \"Snow or Ice Pellets\"] = int(1)\n",
    "                else:\n",
    "                    df0.loc[n, \"Snow or Ice Pellets\"] = int(0)\n",
    "                if(((fr[0]//10000 % 10) + (fr[1]//10000 % 10)) > 1):\n",
    "                    df0.loc[n, \"Rain or Drizzle\"] = int(1)\n",
    "                else:\n",
    "                    df0.loc[n, \"Rain or Drizzle\"] = int(0)\n",
    "                if(((fr[0]//100000 % 10) + (fr[1]//100000 % 10)) > 1):\n",
    "                    df0.loc[n, \"Fog\"] = int(1)\n",
    "                else:\n",
    "                    df0.loc[n, \"Fog\"] = int(0)\n",
    "            \n",
    "            df0 = df0.drop(columns = [\"FRSHTT\"])      \n",
    "            new_usaf = pd.to_numeric(noro_null.loc[i, \"USAF0\"]).astype('int32')\n",
    "            new_wban = pd.to_numeric(noro_null.loc[i, \"WBAN0\"]).astype('int32')\n",
    "            new_filename = str(new_usaf)+str(new_wban) + \"-\" + str(yr) + \"DAILY.csv\"\n",
    "            df0.to_csv(store_path + new_filename)\n",
    "    else:\n",
    "                   continue\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "40bc6677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "x = [1, 0, 2]\n",
    "if 0 in x:\n",
    "    x.remove(0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf98de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.ncei.noaa.gov/data/global-summary-of-the-day/access/2016/72037392824.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
