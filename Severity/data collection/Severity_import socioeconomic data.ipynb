{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "29381dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "salm = pd.read_csv('/Users/evelyn/Desktop/norovirus_complete_better.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dafa0d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.63100329, 8.95581684])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.interpolate as spi\n",
    "a = []\n",
    "x = [0,365,730,1095]\n",
    "y = [1,9,5,6]\n",
    "ipo3=spi.splrep(x,y,k=3)\n",
    "new_x = [12,380]\n",
    "spi.splev(new_x,ipo3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60614d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.63100329, 8.95581684])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "a = []\n",
    "x = [0,365,730,1095]\n",
    "y = [1,9,5,6]\n",
    "cs = CubicSpline(x, y)\n",
    "a.append(cs([12,380]))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3a13210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3287"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "import datetime\n",
    "\n",
    "starttime = datetime.datetime.strptime(str('2010/12/31'), \"%Y/%m/%d\")\n",
    "endtime = datetime.datetime.strptime(str('2019/12/31'), \"%Y/%m/%d\")\n",
    "(endtime - starttime).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0a6efccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac43f3179cbf4614ba96449445ad969a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1953 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The length of `y` along `axis`=0 doesn't match the length of `x`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                 df1 \u001b[38;5;241m=\u001b[39m df1\u001b[38;5;241m.\u001b[39mreset_index(drop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[1;32m     34\u001b[0m                 y\u001b[38;5;241m.\u001b[39mappend(df1\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedian age\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 36\u001b[0m         cs \u001b[38;5;241m=\u001b[39m \u001b[43mCubicSpline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m         med\u001b[38;5;241m.\u001b[39mappend(cs(new_x))\n\u001b[1;32m     39\u001b[0m salm\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedian age\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(med)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/interpolate/_cubic.py:629\u001b[0m, in \u001b[0;36mCubicSpline.__init__\u001b[0;34m(self, x, y, axis, bc_type, extrapolate)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, bc_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot-a-knot\u001b[39m\u001b[38;5;124m'\u001b[39m, extrapolate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 629\u001b[0m     x, dx, y, axis, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[1;32m    632\u001b[0m     bc, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_bc(bc_type, y, y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:], axis)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/interpolate/_cubic.py:48\u001b[0m, in \u001b[0;36mprepare_input\u001b[0;34m(x, y, axis, dydx)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`x` must contain at least 2 elements.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[axis]:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe length of `y` along `axis`=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch the length of `x`\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(axis))\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misfinite(x)):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`x` must contain only finite values.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The length of `y` along `axis`=0 doesn't match the length of `x`"
     ]
    }
   ],
   "source": [
    "# import median age\n",
    "\n",
    "path = '/Users/evelyn/Desktop/socioeconomic/AGE/'\n",
    "\n",
    "x = [0, 365, 731, 1096, 1461, 1826, 2192, 2557, 2922, 3287]\n",
    "initialdate = datetime.datetime.strptime(str('2010/12/31'), \"%Y/%m/%d\")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(len(salm))):\n",
    "    \n",
    "    #填充待测值\n",
    "    new_x = []\n",
    "    startdate = datetime.datetime.strptime(salm.loc[i, \"InitialExposure\"], \"%Y-%m-%d\")\n",
    "    enddate = datetime.datetime.strptime(salm.loc[i, \"LastExposure\"], \"%Y-%m-%d\")\n",
    "    d = startdate\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    while d <= enddate:\n",
    "        new_x.append((d-initialdate).days)\n",
    "        d = d + delta\n",
    "    med = []\n",
    "    for j in range(0,11):\n",
    "        \n",
    "        if(pd.isna(salm.loc[i,\"ExposureCounty\"+str(j+1)])):\n",
    "            break\n",
    "        else:\n",
    "            y = []\n",
    "            for yr in range(0,10):\n",
    "                year = 2010 + yr\n",
    "                filename = str(year) + '.csv'\n",
    "                df = pd.read_csv(path + filename)\n",
    "                df1 = df.loc[df.USPS.str.contains(str(salm.loc[i, \"Exposurestate\"])) & df.County.str.contains(str(salm.loc[i, \"ExposureCounty\"+str(j+1)]))]\n",
    "                if not(len(df1) == 0):\n",
    "                    df1 = df1.reset_index(drop = True) \n",
    "                    y.append(df1.loc[0,\"Median age\"])\n",
    "                    \n",
    "            cs = CubicSpline(x, y)\n",
    "            med.append(cs(new_x))\n",
    "            \n",
    "    salm.loc[i, \"Median age\"] = np.mean(med)\n",
    "            \n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e268ae51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a083c5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb8f71890fa41e79fa2ab921367cd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/711 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import immigration data\n",
    "\n",
    "path = '/Users/evelyn/Desktop/socioeconomic/Migration/'\n",
    "\n",
    "x = [0, 365, 731, 1096, 1461, 1826, 2192, 2557, 2922, 3287]\n",
    "initialdate = datetime.datetime.strptime(str('2010/12/31'), \"%Y/%m/%d\")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(len(salm))):\n",
    "    \n",
    "    #填充待测值\n",
    "    new_x = []\n",
    "    startdate = datetime.datetime.strptime(salm.loc[i, \"InitialExposure\"], \"%Y-%m-%d\")\n",
    "    enddate = datetime.datetime.strptime(salm.loc[i, \"LastExposure\"], \"%Y-%m-%d\")\n",
    "    d = startdate\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    while d <= enddate:\n",
    "        new_x.append((d-initialdate).days)\n",
    "        d = d + delta\n",
    "    med = []\n",
    "    for j in range(0,19):\n",
    "        \n",
    "        if(pd.isna(salm.loc[i,\"ExposureCounty\"+str(j+1)])):\n",
    "            break\n",
    "        else:\n",
    "            y = []\n",
    "            for yr in range(0,10):\n",
    "                year = 2010 + yr\n",
    "                filename = str(year) + '.csv'\n",
    "                df = pd.read_csv(path + filename)\n",
    "                df1 = df.loc[df.USPS.str.contains(str(salm.loc[i, \"Exposurestate\"])) & df.County.str.contains(str(salm.loc[i, \"ExposureCounty\"+str(j+1)]))]\n",
    "                if not(len(df1) == 0):\n",
    "                    df1 = df1.reset_index(drop = True) \n",
    "                    m1 = int(df1.loc[0,'Moved from different county within same state'].replace(\",\",\"\")) + int(df1.loc[0, \"Moved from different state\"].replace(\",\",\"\")) + int(df1.loc[0, \"Moved from abroad\"].replace(\",\",\"\"))\n",
    "                    y.append(m1)\n",
    "                    \n",
    "            cs = CubicSpline(x, y)\n",
    "            med.append(cs(new_x))\n",
    "            \n",
    "    salm.loc[i, \"Immigrants\"] = np.mean(med)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "306af9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd1a744adc645a3af1b317bceb0adfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/711 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import househoulds median income data\n",
    "\n",
    "\n",
    "path = '/Users/evelyn/Desktop/socioeconomic/Income/'\n",
    "\n",
    "x = [0, 365, 731, 1096, 1461, 1826, 2192, 2557, 2922, 3287]\n",
    "initialdate = datetime.datetime.strptime(str('2010/12/31'), \"%Y/%m/%d\")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(len(salm))):\n",
    "    \n",
    "    #填充待测值\n",
    "    new_x = []\n",
    "    startdate = datetime.datetime.strptime(salm.loc[i, \"InitialExposure\"], \"%Y-%m-%d\")\n",
    "    enddate = datetime.datetime.strptime(salm.loc[i, \"LastExposure\"], \"%Y-%m-%d\")\n",
    "    d = startdate\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    while d <= enddate:\n",
    "        new_x.append((d-initialdate).days)\n",
    "        d = d + delta\n",
    "    med = []\n",
    "    for j in range(0,19):\n",
    "        \n",
    "        if(pd.isna(salm.loc[i,\"ExposureCounty\"+str(j+1)])):\n",
    "            break\n",
    "        else:\n",
    "            y = []\n",
    "            for yr in range(0,10):\n",
    "                year = 2010 + yr\n",
    "                filename = str(year) + '.csv'\n",
    "                df = pd.read_csv(path + filename)\n",
    "                df1 = df.loc[df.USPS.str.contains(str(salm.loc[i, \"Exposurestate\"])) & df.County.str.contains(str(salm.loc[i, \"ExposureCounty\"+str(j+1)]))]\n",
    "                if not(len(df1) == 0):\n",
    "                    df1 = df1.reset_index(drop = True) \n",
    "                    m1 = int(df1.loc[0,\"Households Median Income\"])\n",
    "                    y.append(m1)\n",
    "                    \n",
    "            cs = CubicSpline(x, y)\n",
    "            med.append(cs(new_x))\n",
    "            \n",
    "    salm.loc[i, \"Households Median Income\"] = np.mean(med)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae677609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f68d7466094893afede8ed4b0119b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/711 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import agriculture data\n",
    "\n",
    "\n",
    "path = '/Users/evelyn/Desktop/socioeconomic/Agriculture1/'\n",
    "\n",
    "x = [0, 365, 731, 1096, 1461, 1826, 2192, 2557, 2922, 3287]\n",
    "initialdate = datetime.datetime.strptime(str('2010/12/31'), \"%Y/%m/%d\")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(len(salm))):\n",
    "    \n",
    "    #填充待测值\n",
    "    new_x = []\n",
    "    startdate = datetime.datetime.strptime(salm.loc[i, \"InitialExposure\"], \"%Y-%m-%d\")\n",
    "    enddate = datetime.datetime.strptime(salm.loc[i, \"LastExposure\"], \"%Y-%m-%d\")\n",
    "    d = startdate\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    while d <= enddate:\n",
    "        new_x.append((d-initialdate).days)\n",
    "        d = d + delta\n",
    "    med1 = []\n",
    "    med2 = []\n",
    "    for j in range(0,19):\n",
    "        \n",
    "        if(pd.isna(salm.loc[i,\"ExposureCounty\"+str(j+1)])):\n",
    "            break\n",
    "        else:\n",
    "            y1 = []\n",
    "            y2 = []\n",
    "            for yr in range(0,10):\n",
    "                year = 2010 + yr\n",
    "                filename = str(year) + '.csv'\n",
    "                df = pd.read_csv(path + filename)\n",
    "                df1 = df.loc[df.USPS.str.contains(str(salm.loc[i, \"Exposurestate\"])) & df.County.str.contains(str(salm.loc[i, \"ExposureCounty\"+str(j+1)]))]\n",
    "                if not(len(df1) == 0):\n",
    "                    df1.reset_index(drop = True, inplace = True)\n",
    "                    m1 = df1.loc[0,\"%Food preparation\"]\n",
    "                    n1 = df1.loc[0,\"%Farming, fishing, and forestry\"]\n",
    "                    y1.append(m1)\n",
    "                    y2.append(n1)\n",
    "                    \n",
    "            cs1 = CubicSpline(x, y1)\n",
    "            med1.append(cs1(new_x))\n",
    "            \n",
    "            cs2 = CubicSpline(x, y2)\n",
    "            med2.append(cs2(new_x))\n",
    "            \n",
    "    salm.loc[i, \"%Food preparation\"] = np.mean(med1)\n",
    "    salm.loc[i, \"%Farming, fishing, and forestry\"] = np.mean(med2)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9a82a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaedf09400e940b18d5a9d4d899d9e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/711 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Population Density\n",
    "\n",
    "\n",
    "\n",
    "path = '/Users/evelyn/Desktop/socioeconomic/Population Density/'\n",
    "\n",
    "x = [0, 365, 731, 1096, 1461, 1826, 2192, 2557, 2922, 3287]\n",
    "initialdate = datetime.datetime.strptime(str('2010/12/31'), \"%Y/%m/%d\")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(len(salm))):\n",
    "    \n",
    "    #填充待测值\n",
    "    new_x = []\n",
    "    startdate = datetime.datetime.strptime(salm.loc[i, \"InitialExposure\"], \"%Y-%m-%d\")\n",
    "    enddate = datetime.datetime.strptime(salm.loc[i, \"LastExposure\"], \"%Y-%m-%d\")\n",
    "    d = startdate\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    while d <= enddate:\n",
    "        new_x.append((d-initialdate).days)\n",
    "        d = d + delta\n",
    "    med = []\n",
    "    for j in range(0,19):\n",
    "        \n",
    "        if(pd.isna(salm.loc[i,\"ExposureCounty\"+str(j+1)])):\n",
    "            break\n",
    "        else:\n",
    "            y = []\n",
    "            for yr in range(0,10):\n",
    "                year = 2010 + yr\n",
    "                filename = str(year) + '.csv'\n",
    "                df = pd.read_csv(path + filename)\n",
    "                df1 = df.loc[df.USPS.str.contains(str(salm.loc[i, \"Exposurestate\"])) & df.County.str.contains(str(salm.loc[i, \"ExposureCounty\"+str(j+1)]))]\n",
    "                if not(len(df1) == 0):\n",
    "                    df1 = df1.reset_index(drop = True) \n",
    "                    m1 = df1.loc[0,\"Population Density\"]\n",
    "                    y.append(m1)\n",
    "                    \n",
    "            cs = CubicSpline(x, y)\n",
    "            med.append(cs(new_x))\n",
    "            \n",
    "    salm.loc[i, \"Population Density\"] = np.mean(med)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "169f18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "salm = pd.read_csv('/Users/evelyn/Desktop/Cubic spline/salm_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7bb02704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                           0\n",
       "CDCID                                0\n",
       "GenusName                            0\n",
       "InitialExposure                      0\n",
       "LastExposure                         0\n",
       "TotalCases                           0\n",
       "Exposurestate                        0\n",
       "ExposureState                        0\n",
       "ExposureCounty1                      0\n",
       "ExposureCounty2                    635\n",
       "ExposureCounty3                    657\n",
       "ExposureCounty4                    673\n",
       "ExposureCounty5                    682\n",
       "ExposureCounty6                    688\n",
       "ExposureCounty7                    696\n",
       "ExposureCounty8                    699\n",
       "ExposureCounty9                    701\n",
       "ExposureCounty10                   702\n",
       "ExposureCounty11                   704\n",
       "ExposureCounty12                   704\n",
       "ExposureCounty13                   707\n",
       "ExposureCounty14                   708\n",
       "ExposureCounty15                   708\n",
       "ExposureCounty16                   708\n",
       "ExposureCounty17                   709\n",
       "ExposureCounty18                   709\n",
       "ExposureCounty19                   710\n",
       "TEMP                                 0\n",
       "SLP                                 96\n",
       "WDSP                                 5\n",
       "PRCP                                 0\n",
       "RH                                  10\n",
       "SLP-STP                            102\n",
       "MXSPD-WDSP                           5\n",
       "Median age                           0\n",
       "Immigrants                           0\n",
       "Households Median Income             0\n",
       "%Food preparation                    0\n",
       "%Farming, fishing, and forestry      0\n",
       "Population Density                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN Imputation\n",
    "salm.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "657457e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.078 (0.034)\n",
      ">3 0.075 (0.026)\n",
      ">5 0.069 (0.031)\n",
      ">7 0.066 (0.033)\n",
      ">9 0.073 (0.028)\n",
      ">15 0.076 (0.029)\n",
      ">18 0.069 (0.028)\n",
      ">21 0.069 (0.029)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "X = salm[['TEMP','SLP','WDSP','PRCP','RH','SLP-STP','MXSPD-WDSP',\n",
    "            'Median age','Immigrants','Households Median Income','%Food preparation',\n",
    "            '%Farming, fishing, and forestry','Population Density']]\n",
    "y = salm['TotalCases']\n",
    "# evaluate each strategy on the dataset\n",
    "results = list()\n",
    "strategies = [str(i) for i in [1,3,5,7,9,15,18,21]]\n",
    "for s in strategies:\n",
    "    # create the modeling pipeline\n",
    "    pipeline = Pipeline(steps=[('i', KNNImputer(n_neighbors=int(s))), ('m', RandomForestClassifier())])\n",
    "\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # store results\n",
    "    results.append(scores)\n",
    "    print('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03cc0613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'K': 1, 'RMSE': 55.36641902878015},\n",
       " {'K': 3, 'RMSE': 52.43698158842624},\n",
       " {'K': 5, 'RMSE': 50.045318371216425},\n",
       " {'K': 7, 'RMSE': 48.803402197153105},\n",
       " {'K': 9, 'RMSE': 48.847151434168616},\n",
       " {'K': 11, 'RMSE': 48.63757545829854},\n",
       " {'K': 13, 'RMSE': 48.85143208354626},\n",
       " {'K': 15, 'RMSE': 49.058372242143975},\n",
       " {'K': 17, 'RMSE': 48.78555540504556},\n",
       " {'K': 19, 'RMSE': 49.07167106504}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import KNNImputer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "X = salm[['TEMP','SLP','WDSP','PRCP','RH','SLP-STP','MXSPD-WDSP',\n",
    "            'Median age','Immigrants','Households Median Income','%Food preparation',\n",
    "            '%Farming, fishing, and forestry','Population Density']]\n",
    "y = salm['Totalcases']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 89)\n",
    "\n",
    "errors = []\n",
    "train_score = []\n",
    "test_score = []\n",
    "for k in tqdm(range(1, 20, 1)):\n",
    "    X = salm[['TEMP','SLP','WDSP','PRCP','RH','SLP-STP','MXSPD-WDSP',\n",
    "            'Median age','Immigrants','Households Median Income','%Food preparation',\n",
    "            '%Farming, fishing, and forestry','Population Density']]\n",
    "    X = X.astype(np.float32)\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "    imputed = imputer.fit_transform(X)\n",
    "    df_imputed = pd.DataFrame(imputed, columns = X.columns)\n",
    "    \n",
    "    #SLP\n",
    "    X = df_imputed.drop(['SLP'], axis=1)\n",
    "    y = df_imputed['SLP']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    error1 = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    #SLP-STP\n",
    "    X = df_imputed.drop(['SLP-STP'], axis=1)\n",
    "    y = df_imputed['SLP-STP']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    error2 = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    #WDSP\n",
    "    X = df_imputed.drop(['WDSP'], axis=1)\n",
    "    y = df_imputed['WDSP']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    error3 = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    #\n",
    "    X = df_imputed.drop(['MXSPD-WDSP'], axis=1)\n",
    "    y = df_imputed['MXSPD-WDSP']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    error4 = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    #\n",
    "    X = df_imputed.drop(['RH'], axis=1)\n",
    "    y = df_imputed['RH']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    error5 = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    error = error1 + error2 + error3 + error4 + error5\n",
    "    errors.append({'K': k, 'RMSE': error})\n",
    "    \n",
    "errors\n",
    "\n",
    "# we take K = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2ec8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = salm[['TEMP','SLP','WDSP','PRCP','RH','SLP-STP','MXSPD-WDSP',\n",
    "            'Median age','Immigrants','Households Median Income','%Food preparation',\n",
    "            '%Farming, fishing, and forestry','Population Density']]\n",
    "X = X.astype(np.float32)\n",
    "imputer = KNNImputer(n_neighbors=11)\n",
    "imputed = imputer.fit_transform(X)\n",
    "df = pd.DataFrame(imputed, columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98852d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "for i in range(len(salm)):\n",
    "    \n",
    "    if(pd.isna(salm.loc[i, \"SLP-STP\"])):\n",
    "        salm.loc[i, \"SLP-STP\"] = df.loc[i, \"SLP-STP\"]\n",
    "        \n",
    "    if(pd.isna(salm.loc[i, \"SLP\"])):\n",
    "        salm.loc[i, \"SLP\"] = df.loc[i, \"SLP\"]\n",
    "        \n",
    "    if(pd.isna(salm.loc[i, \"RH\"])):\n",
    "        salm.loc[i, \"RH\"] = df.loc[i, \"RH\"]\n",
    "        \n",
    "    if(pd.isna(salm.loc[i, \"WDSP\"])):\n",
    "        salm.loc[i, \"WDSP\"] = df.loc[i, \"WDSP\"]\n",
    "        \n",
    "    if(pd.isna(salm.loc[i, \"MXSPD-WDSP\"])):\n",
    "        salm.loc[i, \"MXSPD-WDSP\"] = df.loc[i, \"MXSPD-WDSP\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b6996b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "salm = pd.read_csv('/Users/evelyn/Desktop/Cubic spline/salm_knn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "921830c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import numpy as np\n",
    "\n",
    "data = salm[['TEMP','SLP','WDSP','PRCP','RH','SLP-STP','MXSPD-WDSP',\n",
    "            'Median age','Immigrants','Households Median Income',\n",
    "             '%Food preparation','%Farming, fishing, and forestry','Population Density']]\n",
    "features = ['TEMP','SLP','WDSP','PRCP','RH','SLP-STP','MXSPD-WDSP',\n",
    "            'Median age','Immigrants','Households Median Income',\n",
    "             '%Food preparation','%Farming, fishing, and forestry','Population Density']\n",
    "import random\n",
    "mean = data.mean()\n",
    "std = data.std()\n",
    "range_low = mean-3*std\n",
    "range_high = mean+3*std\n",
    "new_data = data\n",
    "num=0\n",
    "d = []\n",
    "for i in range(len(salm)):  \n",
    "    for j in range(len(features)):  \n",
    "        if range_low[j] > data.iloc[i,j] or data.iloc[i,j] > range_high[j]:\n",
    "            new_data = new_data.drop([i],axis=0)\n",
    "            d.append(i)\n",
    "            num = num+1\n",
    "            break\n",
    "data = new_data\n",
    "\n",
    "for i in range(len(d)):\n",
    "    salm = salm.drop(d[i],axis=0)\n",
    "    \n",
    "salm.reset_index(drop = True, inplace = True)\n",
    "salm.to_csv('/Users/evelyn/Desktop/Cubic spline/salm_nooutliers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7cdfa854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4408e666b5da446497e8b1c935ba739f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1092 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fea = pd.DataFrame()\n",
    "\n",
    "from itertools import combinations\n",
    "a = []\n",
    "features = ['TEMP','SLP','WDSP','PRCP','RH','SLP-STP','MXSPD-WDSP',\n",
    "            'Median age','Immigrants','Households Median Income','%Food preparation','%Farming, fishing, and forestry','Population Density']\n",
    "for p in combinations(features,9):\n",
    "    a.append(p)\n",
    "for p in combinations(features,10):\n",
    "    a.append(p)\n",
    "for p in combinations(features,11):\n",
    "    a.append(p)\n",
    "for p in combinations(features,12):\n",
    "    a.append(p)\n",
    "\n",
    "import numpy as np\n",
    "from progressbar import ProgressBar\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "r2 = []\n",
    "for i in tqdm(range(len(a))):\n",
    "    fea.loc[i, \"Features\"] = str(a[i])\n",
    "    X = salm[list(a[i])]\n",
    "    y = salm['TotalCases']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 89)\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    model = xgb.XGBRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_xg = model.predict(X_test)\n",
    "    fea.loc[i, \"xgboost\"] = r2_score(y_test, y_pred_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "148e3809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5242658551141702"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea['xgboost'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2227b6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974fc0fe14c14075a006195318da8b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1092 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from progressbar import ProgressBar\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for i in tqdm(range(len(a))):\n",
    "    X = salm[list(a[i])]\n",
    "    y = salm['TotalCases']\n",
    "    dt1 = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 89)\n",
    "    for rm in range(0, 65):\n",
    "        model2 = DecisionTreeRegressor(random_state = rm)\n",
    "        model2.fit(X_train, y_train)\n",
    "        y_pred = model2.predict(X_test)\n",
    "        dt1.append(r2_score(y_test, y_pred))\n",
    "    idx_rf = dt1.index(max(dt1))\n",
    "    fea.loc[i, \"DT89\"] = max(dt1)\n",
    "    fea.loc[i, \"dt_rs\"] = idx_rf   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "24eaa8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5734034308229775"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea['DT89'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b734627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
